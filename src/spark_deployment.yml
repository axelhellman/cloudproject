- hosts: all
  tasks:

   - name: Generate hosts file
     lineinfile: dest=/etc/hosts
                 regexp='.*{{ item }}$'
                 line="{{ hostvars[item].ansible_default_ipv4.address }} {{item}}"
                 state=present
     when: hostvars[item].ansible_default_ipv4.address is defined
     with_items: "{{groups['all']}}"
   - name: Set hostname
     hostname: name="{{inventory_hostname}}"
   
   - name: Include variables
     include_vars: setup_var.yml 



- hosts: sparkmaster

  vars_files:
   - setup_var.yml 

   tasks:
   - name: start jupyter
     shell: runuser -l ubuntu -c 'jupyter notebook --ip=0.0.0.0 --port=60060 &'
     async: 2592000               # 60*60*24*30 â€“ 1 month
     args:
      executable: /bin/bash 
   
   - name: jupyter server token
     shell: cat /home/ubuntu/.local/share/jupyter/runtime/*.json | grep token
     register: token

   - debug:
      var: token.stdout_lines
   
   - name: disable IPv6
     shell: "{{item}}"
     with_items: 
      - echo "net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1" >> /etc/sysctl.conf
      - sysctl -p

   - name: start spark master process
     shell: nohup /usr/local/spark-2.2.2-bin-hadoop2.6/sbin/start-master.sh  &

- hosts: sparkworker
    
  vars_files:
   - setup_var.yml

  tasks:
   - name: disable IPv6
     shell: "{{item}}"
     with_items:
      - echo "net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1" >> /etc/sysctl.conf
      - sysctl -p
 
   - name: start spark worker process
     shell: nohup /usr/local/spark-2.2.2-bin-hadoop2.6/sbin/start-slave.sh spark://sparkmaster:7077 &
